{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def set_seeds(seed: int = 48):\n",
    "    \"\"\"Seed Python, NumPy, and PyTorch for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Set a default seed for the session\n",
    "set_seeds(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Dataset 1_EV charging reports.csv',sep=';')\n",
    "df1.head()\n",
    "df1.info()\n",
    "#df1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2195a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Dataset 6_Local traffic distribution.csv',sep=';')\n",
    "df2.head()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns to proper datetime format\n",
    "df1['Start_plugin'] = pd.to_datetime(df1['Start_plugin'], format='%d.%m.%Y %H:%M')\n",
    "df2['Date_from'] = pd.to_datetime(df2['Date_from'], format='%d.%m.%Y %H:%M')\n",
    "\n",
    "# Sort both dataframes by their datetime columns (required for merge_asof)\n",
    "df1_sorted = df1.sort_values('Start_plugin')\n",
    "df2_sorted = df2.sort_values('Date_from')\n",
    "\n",
    "# Perform merge_asof using the datetime columns with a 1-hour tolerance to avoid distant matches\n",
    "tolerance = pd.Timedelta('1H')\n",
    "ev_charging_traffic = pd.merge_asof(\n",
    "    df1_sorted,\n",
    "    df2_sorted,\n",
    "    left_on='Start_plugin',\n",
    "    right_on='Date_from',\n",
    "    direction='nearest',\n",
    "    tolerance=tolerance\n",
    ")\n",
    "\n",
    "ev_charging_traffic.head()\n",
    "# ev_charging_traffic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edf6e7",
   "metadata": {},
   "source": [
    "What merge_asof does?\n",
    "    Instead of matching exact values (like merge), it:\n",
    "        Matches each row to the nearest timestamp\n",
    "        Usually the previous one\n",
    "        Works only on sorted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f83c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 6878\n",
      "Rows before dropna: 6878\n",
      "Rows after cleaning: 6833 (dropped 45)\n"
     ]
    }
   ],
   "source": [
    "#These will be dropped from the dataframe since they are not needed for the analysis\n",
    "drop_clos = ['session_ID', 'Garage_ID', 'User_ID', 'Shared_ID', 'Plugin_category',\n",
    " 'Duration_category', 'Start_plugin_hour', 'End_plugout_hour', 'End_plugout', \n",
    " 'Start_plugin', 'Date_from' , 'Date_to']\n",
    "\n",
    "ev_charging_traffic.drop(columns=drop_clos, inplace=True)\n",
    "\n",
    "# Identify numeric columns that need conversion (exclude categorical columns)\n",
    "numeric_cols = ['El_kWh', 'Duration_hours', 'KROPPAN BRU', 'MOHOLTLIA', 'SELSBAKK', \n",
    "                'MOHOLT RAMPE 2', 'Jonsvannsveien vest for Steinanvegen']\n",
    "\n",
    "rows_before_cleaning = len(ev_charging_traffic)\n",
    "\n",
    "# Replace comma with dot for numeric columns that are strings, then convert to float\n",
    "# Use pd.to_numeric with errors='coerce' to handle any invalid values (like '-') by converting them to NaN\n",
    "for col in numeric_cols:\n",
    "    if col in ev_charging_traffic.columns:\n",
    "        if ev_charging_traffic[col].dtype == 'object':\n",
    "            # Replace comma with dot, then convert to float (invalid values become NaN)\n",
    "            ev_charging_traffic[col] = ev_charging_traffic[col].str.replace(',', '.')\n",
    "            ev_charging_traffic[col] = pd.to_numeric(ev_charging_traffic[col], errors='coerce')\n",
    "        else:\n",
    "            # Already numeric, just ensure it's float\n",
    "            ev_charging_traffic[col] = ev_charging_traffic[col].astype(float)\n",
    "\n",
    "# Drop rows with missing values introduced by coercion\n",
    "before_dropna = len(ev_charging_traffic)\n",
    "ev_charging_traffic.dropna(inplace=True)\n",
    "rows_after_cleaning = len(ev_charging_traffic)\n",
    "print(f\"Rows before cleaning: {rows_before_cleaning}\")\n",
    "print(f\"Rows before dropna: {before_dropna}\")\n",
    "print(f\"Rows after cleaning: {rows_after_cleaning} (dropped {before_dropna - rows_after_cleaning})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db5e76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "categorical_cols = ['User_type', 'month_plugin', 'weekdays_plugin']\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    ev_charging_traffic[col] = le.fit_transform(ev_charging_traffic[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "analysis_features = ev_charging_traffic.drop(columns=['El_kWh'], axis=1).columns\n",
    "\n",
    "X = ev_charging_traffic[analysis_features]\n",
    "y = ev_charging_traffic['El_kWh']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "490d07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/3000], MSE Loss: 0.6058117747306824\n",
      "Epoch [1000/3000], MSE Loss: 0.576505720615387\n",
      "Epoch [1500/3000], MSE Loss: 0.5625731348991394\n",
      "Epoch [2000/3000], MSE Loss: 0.5512992143630981\n",
      "Epoch [2500/3000], MSE Loss: 0.532048761844635\n",
      "Epoch [3000/3000], MSE Loss: 0.5218437314033508\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float).view(-1,1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float).view(-1,1)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(9,56),\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(56, 28),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(28,1)\n",
    ")\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.007)\n",
    "\n",
    "num_epochs = 3000 # number of training iterations\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train_tensor) # forward pass \n",
    "    mse = loss(outputs, y_train_tensor) # calculate the loss \n",
    "    mse.backward() # backward pass\n",
    "    optimizer.step() # update the weights and biases\n",
    "    optimizer.zero_grad() # reset the gradients to zero\n",
    "\n",
    "    # keep track of the loss during training\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], MSE Loss: {mse.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23cbdc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0144],\n",
       "        [ 0.0818],\n",
       "        [ 0.1194],\n",
       "        ...,\n",
       "        [ 0.1135],\n",
       "        [ 0.0553],\n",
       "        [ 0.0845]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(48)\n",
    "class nn_Regretion(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(nn_Regretion, self).__init__()\n",
    "            self.layer1 = nn.Linear(9,56)\n",
    "            self.layer2 = nn.Linear(56, 28)\n",
    "            self.layer3 = nn.Linear(28,1)\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            #this defines the forward pass\n",
    "            x = self.layer1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.layer3(x)\n",
    "            return x \n",
    "# Optional class-based model (not used for training/evaluation below)\n",
    "optional_model = nn_Regretion()\n",
    "optional_model(X_train_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b696f7f",
   "metadata": {},
   "source": [
    "This is an optional class for appling the neural network class. the code above is simpler however the class can offer reusability if needed. For the purpose of this project, the class is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ee3b1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Test Set MSE (scaled): 0.8194160461425781\n",
      "Neural Network - Test Set MSE (kWh): 115.8997802734375\n",
      "Neural Network - Test Set MAE (kWh): 7.198432445526123\n",
      "Neural Network - Test Set R^2: 0.10924720764160156\n",
      "Baseline (mean) - MSE (kWh): 130.11444091796875\n",
      "Baseline (mean) - MAE (kWh): 8.006174087524414\n",
      "Baseline (mean) - R^2: -1.1920928955078125e-07\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # set the model to evaluation mode\n",
    "with torch.no_grad():  # turns off gradient calculations (which we donâ€™t need outside training)\n",
    "    # Predict on the same scale as training\n",
    "    predictions_scaled = model(X_test_tensor)\n",
    "    test_MSE_pytorch = loss(predictions_scaled, y_test_tensor)\n",
    "\n",
    "# Convert to numpy and back to original kWh scale for interpretability\n",
    "predictions_np = predictions_scaled.detach().numpy()\n",
    "y_test_np = y_test_tensor.detach().numpy()\n",
    "predictions_original = scaler_y.inverse_transform(predictions_np)\n",
    "y_test_original = scaler_y.inverse_transform(y_test_np)\n",
    "\n",
    "# Flatten for metric calculations\n",
    "y_test_original_flat = y_test_original.ravel()\n",
    "predictions_original_flat = predictions_original.ravel()\n",
    "\n",
    "# Baseline predictor: mean of training target\n",
    "baseline_pred = np.full_like(y_test_original_flat, fill_value=y_train.mean())\n",
    "\n",
    "# Metrics\n",
    "mse_scaled = test_MSE_pytorch.item()\n",
    "mse_original = mean_squared_error(y_test_original_flat, predictions_original_flat)\n",
    "mae_original = mean_absolute_error(y_test_original_flat, predictions_original_flat)\n",
    "r2_original = r2_score(y_test_original_flat, predictions_original_flat)\n",
    "\n",
    "baseline_mse = mean_squared_error(y_test_original_flat, baseline_pred)\n",
    "baseline_mae = mean_absolute_error(y_test_original_flat, baseline_pred)\n",
    "baseline_r2 = r2_score(y_test_original_flat, baseline_pred)\n",
    "\n",
    "print('Neural Network - Test Set MSE (scaled):', mse_scaled)\n",
    "print('Neural Network - Test Set MSE (kWh):', float(mse_original))\n",
    "print('Neural Network - Test Set MAE (kWh):', float(mae_original))\n",
    "print('Neural Network - Test Set R^2:', float(r2_original))\n",
    "print('Baseline (mean) - MSE (kWh):', float(baseline_mse))\n",
    "print('Baseline (mean) - MAE (kWh):', float(baseline_mae))\n",
    "print('Baseline (mean) - R^2:', float(baseline_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ad39f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the trained weights for portability\n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
