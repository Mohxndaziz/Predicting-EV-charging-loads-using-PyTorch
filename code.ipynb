{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35dbdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def set_seeds(seed: int = 48):\n",
    "    \"\"\"Seed Python, NumPy, and PyTorch for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Set a default seed for the session\n",
    "set_seeds(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3a5b6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6878 entries, 0 to 6877\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   session_ID         6878 non-null   int64  \n",
      " 1   Garage_ID          6878 non-null   object \n",
      " 2   User_ID            6878 non-null   object \n",
      " 3   User_type          6878 non-null   object \n",
      " 4   Shared_ID          1412 non-null   object \n",
      " 5   Start_plugin       6878 non-null   object \n",
      " 6   Start_plugin_hour  6878 non-null   int64  \n",
      " 7   End_plugout        6844 non-null   object \n",
      " 8   End_plugout_hour   6844 non-null   float64\n",
      " 9   El_kWh             6878 non-null   object \n",
      " 10  Duration_hours     6844 non-null   object \n",
      " 11  month_plugin       6878 non-null   object \n",
      " 12  weekdays_plugin    6878 non-null   object \n",
      " 13  Plugin_category    6878 non-null   object \n",
      " 14  Duration_category  6844 non-null   object \n",
      "dtypes: float64(1), int64(2), object(12)\n",
      "memory usage: 806.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('Dataset 1_EV charging reports.csv',sep=';')\n",
    "df1.head()\n",
    "df1.info()\n",
    "#df1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2195a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10248 entries, 0 to 10247\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                Non-Null Count  Dtype \n",
      "---  ------                                --------------  ----- \n",
      " 0   Date_from                             10248 non-null  object\n",
      " 1   Date_to                               10248 non-null  object\n",
      " 2   KROPPAN BRU                           10248 non-null  object\n",
      " 3   MOHOLTLIA                             10248 non-null  object\n",
      " 4   SELSBAKK                              10248 non-null  object\n",
      " 5   MOHOLT RAMPE 2                        10248 non-null  int64 \n",
      " 6   Jonsvannsveien vest for Steinanvegen  10248 non-null  int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 560.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('Dataset 6_Local traffic distribution.csv',sep=';')\n",
    "df2.head()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7d9ea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dv/pzcw9z617jzfbs0fpgjz5m6w0000gn/T/ipykernel_1558/958114469.py:10: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  tolerance = pd.Timedelta('1H')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_ID</th>\n",
       "      <th>Garage_ID</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>User_type</th>\n",
       "      <th>Shared_ID</th>\n",
       "      <th>Start_plugin</th>\n",
       "      <th>Start_plugin_hour</th>\n",
       "      <th>End_plugout</th>\n",
       "      <th>End_plugout_hour</th>\n",
       "      <th>El_kWh</th>\n",
       "      <th>...</th>\n",
       "      <th>weekdays_plugin</th>\n",
       "      <th>Plugin_category</th>\n",
       "      <th>Duration_category</th>\n",
       "      <th>Date_from</th>\n",
       "      <th>Date_to</th>\n",
       "      <th>KROPPAN BRU</th>\n",
       "      <th>MOHOLTLIA</th>\n",
       "      <th>SELSBAKK</th>\n",
       "      <th>MOHOLT RAMPE 2</th>\n",
       "      <th>Jonsvannsveien vest for Steinanvegen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-21 10:20:00</td>\n",
       "      <td>10</td>\n",
       "      <td>21.12.2018 10:23</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0,3</td>\n",
       "      <td>...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>late morning (9-12)</td>\n",
       "      <td>Less than 3 hours</td>\n",
       "      <td>2018-12-21 10:00:00</td>\n",
       "      <td>21.12.2018 11:00</td>\n",
       "      <td>3244</td>\n",
       "      <td>1632</td>\n",
       "      <td>545</td>\n",
       "      <td>194</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-21 10:24:00</td>\n",
       "      <td>10</td>\n",
       "      <td>21.12.2018 10:32</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0,87</td>\n",
       "      <td>...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>late morning (9-12)</td>\n",
       "      <td>Less than 3 hours</td>\n",
       "      <td>2018-12-21 10:00:00</td>\n",
       "      <td>21.12.2018 11:00</td>\n",
       "      <td>3244</td>\n",
       "      <td>1632</td>\n",
       "      <td>545</td>\n",
       "      <td>194</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-4</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-21 11:33:00</td>\n",
       "      <td>11</td>\n",
       "      <td>21.12.2018 19:46</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29,87</td>\n",
       "      <td>...</td>\n",
       "      <td>Friday</td>\n",
       "      <td>late morning (9-12)</td>\n",
       "      <td>Between 6 and 9  hours</td>\n",
       "      <td>2018-12-21 12:00:00</td>\n",
       "      <td>21.12.2018 13:00</td>\n",
       "      <td>4107</td>\n",
       "      <td>2013</td>\n",
       "      <td>640</td>\n",
       "      <td>260</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-2</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-22 16:15:00</td>\n",
       "      <td>16</td>\n",
       "      <td>23.12.2018 16:40</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15,56</td>\n",
       "      <td>...</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>late afternoon (15-18)</td>\n",
       "      <td>More than 18 hours</td>\n",
       "      <td>2018-12-22 16:00:00</td>\n",
       "      <td>22.12.2018 17:00</td>\n",
       "      <td>3052</td>\n",
       "      <td>1484</td>\n",
       "      <td>453</td>\n",
       "      <td>224</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AdO3</td>\n",
       "      <td>AdO3-2</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-24 22:03:00</td>\n",
       "      <td>22</td>\n",
       "      <td>24.12.2018 23:02</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3,62</td>\n",
       "      <td>...</td>\n",
       "      <td>Monday</td>\n",
       "      <td>late evening (21-midnight)</td>\n",
       "      <td>Less than 3 hours</td>\n",
       "      <td>2018-12-24 22:00:00</td>\n",
       "      <td>24.12.2018 23:00</td>\n",
       "      <td>1390</td>\n",
       "      <td>693</td>\n",
       "      <td>226</td>\n",
       "      <td>83</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_ID Garage_ID User_ID User_type Shared_ID        Start_plugin  \\\n",
       "0           1      AdO3  AdO3-4   Private       NaN 2018-12-21 10:20:00   \n",
       "1           2      AdO3  AdO3-4   Private       NaN 2018-12-21 10:24:00   \n",
       "2           3      AdO3  AdO3-4   Private       NaN 2018-12-21 11:33:00   \n",
       "3           4      AdO3  AdO3-2   Private       NaN 2018-12-22 16:15:00   \n",
       "4           5      AdO3  AdO3-2   Private       NaN 2018-12-24 22:03:00   \n",
       "\n",
       "   Start_plugin_hour       End_plugout  End_plugout_hour El_kWh  ...  \\\n",
       "0                 10  21.12.2018 10:23              10.0    0,3  ...   \n",
       "1                 10  21.12.2018 10:32              10.0   0,87  ...   \n",
       "2                 11  21.12.2018 19:46              19.0  29,87  ...   \n",
       "3                 16  23.12.2018 16:40              16.0  15,56  ...   \n",
       "4                 22  24.12.2018 23:02              23.0   3,62  ...   \n",
       "\n",
       "  weekdays_plugin             Plugin_category       Duration_category  \\\n",
       "0          Friday         late morning (9-12)       Less than 3 hours   \n",
       "1          Friday         late morning (9-12)       Less than 3 hours   \n",
       "2          Friday         late morning (9-12)  Between 6 and 9  hours   \n",
       "3        Saturday      late afternoon (15-18)      More than 18 hours   \n",
       "4          Monday  late evening (21-midnight)       Less than 3 hours   \n",
       "\n",
       "            Date_from           Date_to KROPPAN BRU MOHOLTLIA SELSBAKK  \\\n",
       "0 2018-12-21 10:00:00  21.12.2018 11:00        3244      1632      545   \n",
       "1 2018-12-21 10:00:00  21.12.2018 11:00        3244      1632      545   \n",
       "2 2018-12-21 12:00:00  21.12.2018 13:00        4107      2013      640   \n",
       "3 2018-12-22 16:00:00  22.12.2018 17:00        3052      1484      453   \n",
       "4 2018-12-24 22:00:00  24.12.2018 23:00        1390       693      226   \n",
       "\n",
       "  MOHOLT RAMPE 2 Jonsvannsveien vest for Steinanvegen  \n",
       "0            194                                  622  \n",
       "1            194                                  622  \n",
       "2            260                                  785  \n",
       "3            224                                  694  \n",
       "4             83                                  353  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert datetime columns to proper datetime format\n",
    "df1['Start_plugin'] = pd.to_datetime(df1['Start_plugin'], format='%d.%m.%Y %H:%M')\n",
    "df2['Date_from'] = pd.to_datetime(df2['Date_from'], format='%d.%m.%Y %H:%M')\n",
    "\n",
    "# Sort both dataframes by their datetime columns (required for merge_asof)\n",
    "df1_sorted = df1.sort_values('Start_plugin')\n",
    "df2_sorted = df2.sort_values('Date_from')\n",
    "\n",
    "# Perform merge_asof using the datetime columns with a 1-hour tolerance to avoid distant matches\n",
    "tolerance = pd.Timedelta('1H')\n",
    "ev_charging_traffic = pd.merge_asof(\n",
    "    df1_sorted,\n",
    "    df2_sorted,\n",
    "    left_on='Start_plugin',\n",
    "    right_on='Date_from',\n",
    "    direction='nearest',\n",
    "    tolerance=tolerance\n",
    ")\n",
    "\n",
    "ev_charging_traffic.head()\n",
    "# ev_charging_traffic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edf6e7",
   "metadata": {},
   "source": [
    "What merge_asof does?\n",
    "    Instead of matching exact values (like merge), it:\n",
    "        Matches each row to the nearest timestamp\n",
    "        Usually the previous one\n",
    "        Works only on sorted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f83c48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 6878\n",
      "Rows before dropna: 6878\n",
      "Rows after cleaning: 6833 (dropped 45)\n"
     ]
    }
   ],
   "source": [
    "#These will be dropped from the dataframe since they are not needed for the analysis\n",
    "drop_clos = ['session_ID', 'Garage_ID', 'User_ID', 'Shared_ID', 'Plugin_category',\n",
    " 'Duration_category', 'Start_plugin_hour', 'End_plugout_hour', 'End_plugout', \n",
    " 'Start_plugin', 'Date_from' , 'Date_to']\n",
    "\n",
    "ev_charging_traffic.drop(columns=drop_clos, inplace=True)\n",
    "\n",
    "# Identify numeric columns that need conversion (exclude categorical columns)\n",
    "numeric_cols = ['El_kWh', 'Duration_hours', 'KROPPAN BRU', 'MOHOLTLIA', 'SELSBAKK', \n",
    "                'MOHOLT RAMPE 2', 'Jonsvannsveien vest for Steinanvegen']\n",
    "\n",
    "rows_before_cleaning = len(ev_charging_traffic)\n",
    "\n",
    "# Replace comma with dot for numeric columns that are strings, then convert to float\n",
    "# Use pd.to_numeric with errors='coerce' to handle any invalid values (like '-') by converting them to NaN\n",
    "for col in numeric_cols:\n",
    "    if col in ev_charging_traffic.columns:\n",
    "        if ev_charging_traffic[col].dtype == 'object':\n",
    "            # Replace comma with dot, then convert to float (invalid values become NaN)\n",
    "            ev_charging_traffic[col] = ev_charging_traffic[col].str.replace(',', '.')\n",
    "            ev_charging_traffic[col] = pd.to_numeric(ev_charging_traffic[col], errors='coerce')\n",
    "        else:\n",
    "            # Already numeric, just ensure it's float\n",
    "            ev_charging_traffic[col] = ev_charging_traffic[col].astype(float)\n",
    "\n",
    "# Drop rows with missing values introduced by coercion\n",
    "before_dropna = len(ev_charging_traffic)\n",
    "ev_charging_traffic.dropna(inplace=True)\n",
    "rows_after_cleaning = len(ev_charging_traffic)\n",
    "print(f\"Rows before cleaning: {rows_before_cleaning}\")\n",
    "print(f\"Rows before dropna: {before_dropna}\")\n",
    "print(f\"Rows after cleaning: {rows_after_cleaning} (dropped {before_dropna - rows_after_cleaning})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db5e76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "categorical_cols = ['User_type', 'month_plugin', 'weekdays_plugin']\n",
    "encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    ev_charging_traffic[col] = le.fit_transform(ev_charging_traffic[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "analysis_features = ev_charging_traffic.drop(columns=['El_kWh'], axis=1).columns\n",
    "\n",
    "X = ev_charging_traffic[analysis_features]\n",
    "y = ev_charging_traffic['El_kWh']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "490d07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [500/3000], MSE Loss: 0.6058117747306824\n",
      "Epoch [1000/3000], MSE Loss: 0.576505720615387\n",
      "Epoch [1500/3000], MSE Loss: 0.5625731348991394\n",
      "Epoch [2000/3000], MSE Loss: 0.5512992143630981\n",
      "Epoch [2500/3000], MSE Loss: 0.532048761844635\n",
      "Epoch [3000/3000], MSE Loss: 0.5218437314033508\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float).view(-1,1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float).view(-1,1)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(9,56),\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(56, 28),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(28,1)\n",
    ")\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.007)\n",
    "\n",
    "num_epochs = 3000 # number of training iterations\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train_tensor) # forward pass \n",
    "    mse = loss(outputs, y_train_tensor) # calculate the loss \n",
    "    mse.backward() # backward pass\n",
    "    optimizer.step() # update the weights and biases\n",
    "    optimizer.zero_grad() # reset the gradients to zero\n",
    "\n",
    "    # keep track of the loss during training\n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], MSE Loss: {mse.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "23cbdc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0144],\n",
       "        [ 0.0818],\n",
       "        [ 0.1194],\n",
       "        ...,\n",
       "        [ 0.1135],\n",
       "        [ 0.0553],\n",
       "        [ 0.0845]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(48)\n",
    "class nn_Regretion(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(nn_Regretion, self).__init__()\n",
    "            self.layer1 = nn.Linear(9,56)\n",
    "            self.layer2 = nn.Linear(56, 28)\n",
    "            self.layer3 = nn.Linear(28,1)\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            #this defines the forward pass\n",
    "            x = self.layer1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.layer3(x)\n",
    "            return x \n",
    "# Optional class-based model (not used for training/evaluation below)\n",
    "optional_model = nn_Regretion()\n",
    "optional_model(X_train_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b696f7f",
   "metadata": {},
   "source": [
    "This is an optional class for appling the neural network class. the code above is simpler however the class can offer reusability if needed. For the purpose of this project, the class is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ee3b1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Test Set MSE (scaled): 0.8194160461425781\n",
      "Neural Network - Test Set MSE (kWh): 115.8997802734375\n",
      "Neural Network - Test Set MAE (kWh): 7.198432445526123\n",
      "Neural Network - Test Set R^2: 0.10924720764160156\n",
      "Baseline (mean) - MSE (kWh): 130.11444091796875\n",
      "Baseline (mean) - MAE (kWh): 8.006174087524414\n",
      "Baseline (mean) - R^2: -1.1920928955078125e-07\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # set the model to evaluation mode\n",
    "with torch.no_grad():  # turns off gradient calculations (which we don’t need outside training)\n",
    "    # Predict on the same scale as training\n",
    "    predictions_scaled = model(X_test_tensor)\n",
    "    test_MSE_pytorch = loss(predictions_scaled, y_test_tensor)\n",
    "\n",
    "# Convert to numpy and back to original kWh scale for interpretability\n",
    "predictions_np = predictions_scaled.detach().numpy()\n",
    "y_test_np = y_test_tensor.detach().numpy()\n",
    "predictions_original = scaler_y.inverse_transform(predictions_np)\n",
    "y_test_original = scaler_y.inverse_transform(y_test_np)\n",
    "\n",
    "# Flatten for metric calculations\n",
    "y_test_original_flat = y_test_original.ravel()\n",
    "predictions_original_flat = predictions_original.ravel()\n",
    "\n",
    "# Baseline predictor: mean of training target\n",
    "baseline_pred = np.full_like(y_test_original_flat, fill_value=y_train.mean())\n",
    "\n",
    "# Metrics\n",
    "mse_scaled = test_MSE_pytorch.item()\n",
    "mse_original = mean_squared_error(y_test_original_flat, predictions_original_flat)\n",
    "mae_original = mean_absolute_error(y_test_original_flat, predictions_original_flat)\n",
    "r2_original = r2_score(y_test_original_flat, predictions_original_flat)\n",
    "\n",
    "baseline_mse = mean_squared_error(y_test_original_flat, baseline_pred)\n",
    "baseline_mae = mean_absolute_error(y_test_original_flat, baseline_pred)\n",
    "baseline_r2 = r2_score(y_test_original_flat, baseline_pred)\n",
    "\n",
    "print('Neural Network - Test Set MSE (scaled):', mse_scaled)\n",
    "print('Neural Network - Test Set MSE (kWh):', float(mse_original))\n",
    "print('Neural Network - Test Set MAE (kWh):', float(mae_original))\n",
    "print('Neural Network - Test Set R^2:', float(r2_original))\n",
    "print('Baseline (mean) - MSE (kWh):', float(baseline_mse))\n",
    "print('Baseline (mean) - MAE (kWh):', float(baseline_mae))\n",
    "print('Baseline (mean) - R^2:', float(baseline_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ad39f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the trained weights for portability\n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
